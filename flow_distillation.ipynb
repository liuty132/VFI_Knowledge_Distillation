{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import *\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from model.pytorch_msssim import ssim_matlab\n",
    "import numpy as np\n",
    "import cv2\n",
    "import math\n",
    "import pickle\n",
    "import ossaudiodev\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda\")\n",
    "teacher_model = EMA_VFI_Model()\n",
    "teacher_model.load_model('ours')\n",
    "teacher_model.eval()\n",
    "teacher_model.net.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, list_path, path=\"/content/Project1/vimeo_triplet/\"):\n",
    "    model.eval()\n",
    "    f = open(list_path, 'r')\n",
    "    psnr_list = []\n",
    "    ssim_list = []\n",
    "    cnt = 0\n",
    "    for i in f:\n",
    "        name = str(i).strip()\n",
    "        if(len(name) <= 1):\n",
    "            continue\n",
    "        # print(path + 'sequences/' + name + '/im1.png')\n",
    "        I0 = cv2.imread(path + 'sequences/' + name + '/im1.png')\n",
    "        I1 = cv2.imread(path + 'sequences/' + name + '/im2.png')\n",
    "        I2 = cv2.imread(path + 'sequences/' + name + '/im3.png')\n",
    "        I0 = (torch.tensor(I0.transpose(2, 0, 1)).to(DEVICE) / 255.).unsqueeze(0)\n",
    "        I2 = (torch.tensor(I2.transpose(2, 0, 1)).to(DEVICE) / 255.).unsqueeze(0)\n",
    "        mid = model.inference(I0, I2)[0][0]\n",
    "        ssim = ssim_matlab(torch.tensor(I1.transpose(2, 0, 1)).to(DEVICE).unsqueeze(0) / 255., torch.round(mid * 255).unsqueeze(0) / 255.).detach().cpu().numpy()\n",
    "        mid = np.round((mid * 255).detach().cpu().numpy()).astype('uint8').transpose(1, 2, 0) / 255.\n",
    "        I1 = I1 / 255.\n",
    "        psnr = -10 * math.log10(((I1 - mid) * (I1 - mid)).mean())\n",
    "        psnr_list.append(psnr)\n",
    "        ssim_list.append(ssim)\n",
    "    print(\"Avg PSNR: {} SSIM: {}\".format(np.mean(psnr_list), np.mean(ssim_list)))\n",
    "    return psnr_list, ssim_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VimeoDataset(Dataset):\n",
    "    def __init__(self, dataset_dir, triplet_list_file, train=True):\n",
    "        self.dataset_dir = dataset_dir\n",
    "        self.triplet_list_file = triplet_list_file\n",
    "        self.train = train\n",
    "        self.triplets = self._load_triplets()\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.ToTensor()\n",
    "        ])\n",
    "\n",
    "    def _load_triplets(self):\n",
    "        triplets = []\n",
    "        with open(self.triplet_list_file, 'r') as f:\n",
    "            for line in f:\n",
    "                triplets.append(line.strip())\n",
    "        return triplets\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.triplets)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        triplet_path = self.triplets[idx]\n",
    "        img1_path = os.path.join(self.dataset_dir, triplet_path, 'im1.png')\n",
    "        img2_path = os.path.join(self.dataset_dir, triplet_path, 'im2.png') # Ground Truth\n",
    "        img3_path = os.path.join(self.dataset_dir, triplet_path, 'im3.png')\n",
    "        # Load images\n",
    "        img1 = Image.open(img1_path).convert('RGB')\n",
    "        img2 = Image.open(img2_path).convert('RGB') \n",
    "        img3 = Image.open(img3_path).convert('RGB')\n",
    "        # Convert to tensor first\n",
    "        img1 = self.transform(img1)\n",
    "        img2 = self.transform(img2)\n",
    "        img3 = self.transform(img3)\n",
    "        # Concatenate img1 and img3 for model input\n",
    "        imgs = torch.cat((img1, img3), dim=0) \n",
    "        return {'imgs': imgs, 'gt': img2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIMEO_DIR = \"vimeo_triplet/sequences\"\n",
    "TRAIN_LIST = \"vimeo_triplet/tri_trainlist.txt\"\n",
    "VAL_LIST = \"vimeo_triplet/tri_vallist.txt\"\n",
    "TEST_LIST = \"vimeo_triplet/tri_testlist.txt\"\n",
    "\n",
    "train_dataset = VimeoDataset(\n",
    "    dataset_dir=VIMEO_DIR,\n",
    "    triplet_list_file=TRAIN_LIST,\n",
    "    train=True\n",
    ")\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flow_distill(train_loader, path_idx, num_epoch=10, lr=1e-6, flow_distill_weight=0.0005, output_path=\"/content/drive/MyDrive/EE 641/Project/\"):\n",
    "    os.mkdir(output_path+path_idx+\"flow_distill_res\")\n",
    "    student_model = RIFE_Model()\n",
    "    student_model.load_model('ckpt')\n",
    "    student_model.flownet.to(DEVICE)\n",
    "    losses_g, losses_flow = [], []\n",
    "    for epoch in range(num_epoch):\n",
    "        student_model.train()\n",
    "        teacher_model.eval()\n",
    "        total_loss_g = 0\n",
    "        total_loss_flow = 0\n",
    "        loss_g, loss_flow = [], []\n",
    "        for i, data in enumerate(train_loader):\n",
    "            imgs = data['imgs'].to(DEVICE, non_blocking=True)\n",
    "            gt = data['gt'].to(DEVICE, non_blocking=True)\n",
    "            _, loss_dict = student_model.update_flow_distill(\n",
    "                imgs,\n",
    "                gt,\n",
    "                learning_rate=lr,\n",
    "                training=True,\n",
    "                teacher_model=teacher_model,\n",
    "                flow_distill_weight=flow_distill_weight\n",
    "            )\n",
    "            # Append loss\n",
    "            current_loss_g = loss_dict['loss_l1'] + loss_dict['loss_tea'] + loss_dict['loss_distill'] * 0.01\n",
    "            current_loss_flow = loss_dict['loss_flow_distill']\n",
    "            total_loss_g += current_loss_g.item()\n",
    "            total_loss_flow += current_loss_flow.item()\n",
    "            loss_g.append(current_loss_g.item())\n",
    "            loss_flow.append(current_loss_flow.item())\n",
    "            # Current batch evaluate, save checkpoint\n",
    "            if (i + 1) % 100 == 0:\n",
    "                psnr_list, ssim_list = evaluate(student_model, list_path='/content/drive/MyDrive/EE 641/Project/vimeo_triplet/tri_vallist.txt')\n",
    "            if (i) % 20 == 0:\n",
    "                print(f\"Epoch {epoch} Batch {i+1}/{len(train_loader)}, \"\n",
    "                    f\"RIFE Loss: {current_loss_g.item():.4f}, \"\n",
    "                    f\"Flow Distill Loss: {current_loss_flow.item():.4f}\")\n",
    "                torch.save(student_model.flownet.state_dict(), f\"{output_path}{path_idx}flow_distill_res/epoch_{epoch+1}_batch_{i+1}.pkl\")\n",
    "        # Current epoch evaluate\n",
    "        avg_loss_g = total_loss_g / len(train_loader)\n",
    "        avg_loss_flow = total_loss_flow / len(train_loader)\n",
    "        print(f\"Epoch {epoch+1}/{num_epoch} finished. Avg RIFE Loss: {avg_loss_g:.4f}, Avg Flow Distill Loss: {avg_loss_flow:.4f}\")\n",
    "        losses_g.append(loss_g)\n",
    "        losses_flow.append(loss_flow)\n",
    "        with open(f'{output_path}{path_idx}flow_distill_res/losses_g.pkl', 'wb') as f:\n",
    "            pickle.dump(losses_g, f)\n",
    "        with open(f'{output_path}{path_idx}flow_distill_res/losses_flow.pkl', 'wb') as f:\n",
    "            pickle.dump(losses_flow, f)\n",
    "    # Save final checkpoint\n",
    "    torch.save(student_model.flownet.state_dict(), f\"{output_path}{path_idx}flow_distill_res/final.pkl\")\n",
    "    print(f\"Final checkpoint saved for Flow Distillation Weight: {flow_distill_weight}\")\n",
    "    psnr_list, ssim_list = evaluate(student_model, list_path='/content/Project1/vimeo_triplet/tri_testlist.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_distill(train_loader, '0005', 20)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
